LET'S UNDERSTAND THE MYSTERY OF DOCKER üòÅ

# Why use DOCKER:- Docker helps to ease installation of softwares , applications (without worrying about setup and dependencies). not only on your PC but on web server or cloud based platform.
# docker run -it redis :- an instance of redis up and run on my computer 
# What is DOCKER:- It is a platform or ecosystem around creating and running containers.
# DOCKER ecosystem :- Docker Client, Docker Server, Docker Machine, Docker Images, Docker Hub, Docker Compose.
# Containers:- 
When running the command like:- docker run -it redis (When running this command the Dokcer CLI reached out to Docker Hub and downloaded a single file called an "image" # Image :- An image is a single file that containing all dependencies and all configurations to run a very specific program For e.g Reddis, Jupiter
This single file is stored on your hardrive and we can use this image to create a container . # Container :- Container is an instance of an image , like a running program , So we can say Container is a program with its own isolated set of hardware resources .
a "container" is really a process or a set of processes that have a grouping of resourcesspecifically assigned to it.
# DOCKER CLI (client):- a tool that is used to issue commands 
# DOCKER SERVER/ DOCKER Daemon :- a tool that is responsible for creating images, running containers etc. 
# The wsl command in Windows is used to interact with the Windows Subsystem for Linux (WSL).

# Let docker run hello-world :- This commands starts the "Docker CLI" which is in charge of taking commands and do a little bit processing and then communicating the commands to "Docker server" which is really in charge of heavy lifting . 
So "docker run hello-world" means that we want to start up a new container using the image with name of hello-world , the hello-world image has a tiny little program inside of it . "DOCKER server" saw that we are trying to up a new container using an image called hello world , The first thing that DOCKER server did was to check to see if it already had a local copy of the hello world image or that hello world file , So Docker server look into image cache , If Image Cache is empty as we just dowload docker , so Docker server will reach out to a free service called Docker Hub, The Docker Hub is a repository of free public images so you can freely download and run on your personal computer.So, Docker server reached out to Docker Hub and said,"Hey, I'm looking for an image called hello world.Do you have one?"Of course, the Docker hub does.So, Docker server downloaded this hello world file and stored it on your personal computer in this ImageCache where it can now be reran at some point in the future very quickly without having to re-download it from the Docker Hub.After that, the Docker server then said,"Okay, great. I've got this image and now, it's time to use it to create an instance of a container."So, the Docker server then essentially took that single file,loaded it up into memory,created a container out of it,and then ran a single program inside of it.

# Namespacing:- Isolating resources per process(or grp of process)
# Control grps (cgrps):- Limit amount of resources used per process
So, namespacing is for saying,"Hey, this area of the hard drive is for this process."A control group can be used to limit the amount of memory that a process can use, the amount of CPU,the amount of hard drive input, output.
So, these two features put together can be used to really kind of isolate a single process and limit the amount of resources it can talk to,and the amount of bandwidth  essentially,that it can make use of.
a "container" is really a process or a set of processes that have a grouping of resourcesspecifically assigned to it.

So namespacing , control groups belong to Linux, not to Windows, not to macOS. So that might make you kind of question or wonder how are you running Docker right now? You know, we are running a Docker client and we are running Docker containers on a macOS or a Windows operating system. How is that happening if these are Linux-specific features? Well, here's what's happening behind the scenes. When you installed Docker for Windows or Docker for Mac just a moment ago in the last couple sections, you installed a Linux virtual machine. So, so long as Docker up here is running, you technically have a Linux virtual machine running on your computer. Inside of this virtual machine is where all of these containers are going to be created. So inside the virtual machine, we have a Linux kernel, and that Linux kernel is going to be hosting, running processes inside of containers. And it's that Linux kernel that's going to be in charge of limiting access or kind of constraining access or isolating access to different hardware resources on your computer.


@ command to create , run a container using image :- "docker run <image name>" , docker:- Reference the docker client , run :- try to create and run a container , <image name>:- name of image to use for this container 
e.g:- The command docker run busybox is used to run a Docker container based on the "busybox" image. The "busybox" image is a lightweight and minimalistic image that includes a basic set of common Linux utilities. This image is often used for debugging, testing, or creating small and efficient containers.
"docker run -it busybox sh":- The command docker run -it busybox sh is used to start a Docker container based on the "busybox" image and run the sh (Bourne shell) command interactively inside the container.So, when run docker run -it busybox sh, we essentially starting a new container based on the "busybox" image and opening an interactive shell session inside that container.

When you run the docker run busybox command, Docker will check if the "busybox" image is available locally. If it's not available, Docker will automatically pull the "busybox" image from the Docker Hub. Once the image is available, a new container will be started, and it will execute the default command specified by the "busybox" image.
@ command to list all running containers :- "docker ps" , docker:- Reference the docker client, ps"- list all running containers 
@ command to listing of all the containers that we have ever created :- "docker ps --all"
@ command to create a new container but does not start it. It allows you to configure and customize the container's settings before starting it :-
"docker create [OPTIONS] IMAGE [COMMAND] [ARG...]" e.g:- docker create -it --name my_container ubuntu /bin/bash(creates a new container named my_container from the ubuntu image and runs an interactive shell.)
@ command  to start one or more stopped containers :- "docker start [OPTIONS] CONTAINER [CONTAINER...]" , e.g :- docker start my_container
@ Start a Stopped Container:- docker start CONTAINER_ID or CONTAINER_NAME
@ Stop a Running Container:- docker stop CONTAINER_ID or CONTAINER_NAME
@ command to forcefully terminate a running container:- docker kill [OPTIONS] CONTAINER [CONTAINER...]
# docker stop attempts a graceful shutdown by sending a SIGTERM signal first, allowing the container to perform cleanup operations. If the container doesn't stop within the specified timeout, it is forcefully terminated with a SIGKILL.
docker kill forcefully terminates the container by immediately sending a SIGKILL signal without attempting a graceful shutdown.
@ Delete all containers ( to clean up unused data, including stopped containers, volumes, networks, and unreferenced images):- docker system prune 
@ Remove a specific container :- docker rm CONTAINER_ID or CONTAINER_NAME
@ Remove multiple containers :- docker rm container1 container2
@ command  to view the logs generated by a running or stopped container:- "docker logs [OPTIONS] CONTAINER"
@ command used to run commands inside a running container(Execute an additional command in a container):- docker exec -it <container id > <command> (The docker exec command is used to run commands inside a running container. The -it(allow us to provide input to the container) flags are commonly used with docker exec to interact with the container's STDIN (standard input) and allocate a pseudo-TTY (terminal) )

# docker file:- A dockerfile is essentially a plain text file that is going to have a couple of lines of configuration placed inside of it.Inside of every dockerfile,we're always going to specify a base image.It's going to be one of the first things we have to do.After that, we'll add in some additional configuration to run commands to add in some dependencies or some more software, some more programs that we need to successfully create and execute our container.And then finally we will specify a startup commandfor the image.So anytime we take that image and create a container out of it,it will be the command that is executed to essentially boot up or start the container.
# FROM command use to specify the docker image that we want to use as a base
# RUN command use to execute some command while we are preparing our custom image 
# CMD or command instruction specifies what should be executed when our image is used to start up a new container 
# The docker build . command is used to build a Docker image based on the instructions provided in the Dockerfile located in the current directory (.). The docker build command is a fundamental step in the process of creating a Docker image from your application code and configurations.

# "Image tagging" is a way to provide a human-readable and meaningful label to an image. It helps identify and version your images, making it easier to manage and share them. The -t option in the docker build command is used to specify a tag for the image.
e.g:- docker build -t jatik_learning_image/redis:latest .
docker build: This is the command used to build a Docker image.

-t jatik_learning_image/redis:latest: The -t option allows you to tag the image with a name and, optionally, a tag. In this case:jatik_learning_image/redis is the repository name. It's common to use a format like <username or organization>/<imagename> to provide a unique identifier.
"latest" is the tag. The tag is used to version your images. In this example, latest is often used to indicate the most recent version of the image
Docker will build an image based on the Dockerfile in the current directory, and it will be tagged as jatik_learning_image/redis:latest. The resulting image can then be referenced using this tag in subsequent commands or when pushing the image to a container registry.

# Running the command docker run jatik_learning_image/redis creates and starts a container based on the Docker image with the specified tag (jatik_learning_image/redis)
COMING SOON: API-Driven Bare Metal with Intel¬Æ MAX 1100 GPUs!



Introduction

Docker is a popular tool for deploying and running containerized applications. It is known for its reliability, resource efficiency, and scalability, making it a frequent choice for development teams.

In this article, you will learn what Docker is, its essential components, and the pros and cons of using the platform.

What is Docker?
Introduction to Containerization
Containerization is a development process that involves shipping an application and the dependencies necessary for its operation in an executable unit called the container. The concept of a container is explained in detail in the following sections.

What Are Containers?
Containers are lightweight virtualized runtime environments for running applications. A container represents a software package with code, system tools, runtime, libraries, dependencies, and configuration files required for running a specific application. Each container is independent and isolated from the host and other containers.

A template containing instructions and data necessary to build the container is called an image. Images are immutable (i.e., they cannot be changed), so any modification in the structure and content requires creating a new Docker image.

Containers vs. Virtual Machines
Containers perform virtualization at the application level. It means they share the operating system kernel with the host and virtualize on top of it.

Virtual machines are entirely independent of the host OS because they sit atop a hypervisor that isolates them. Each VM requires its own operating system, which can differ from the host's.

The diagram below illustrates the difference between containers and virtual machines.

Docker containers vs virtual machines.
Virtual machines often consume a lot of host system resources. A VM running a small web app still needs to run the entire OS in the background.

Containers are lightweight, fast, and simple to configure. They allow developers to work on the same application in different environments without affecting performance.

Note: To maximize container performance, implement Docker container management best practices.

Why Use Containers?
Containers bring numerous benefits to the software development process. Integrating containers into a development workflow allows developers to:

Run multiple workloads on fewer resources.
Isolate and segregate applications.
Standardize environments to ensure consistency across development and release cycles.
Streamline the software development lifecycle (SDLC) and support other CI/CD workflows.
Develop highly portable workloads that can run on multi-cloud platforms.
Introduce an effective version control system for an application.
What Is Docker?
Docker is an open-source containerization platform for developing, deploying, and managing container applications. The project started as a Platform as a Service solution called DotCloud. However, many developers showed great interest in the underlying technology, software containers, which soon became the platform's focus.

Developer teams mainly use Docker to create distributed applications that work efficiently in different environments. By making the software system agnostic, Docker eliminates compatibility issues and allows the creation of cross-platform apps.

How Does Docker Work?
Docker is a client-server platform, i.e., it enables multiple clients to control deployments on a single server. The following sections explain the essential elements of Docker's architecture, introduce Docker objects and list tools commonly used with the platform.

Docker Architecture
The main element of Docker architecture is the Docker Engine (DE). It comprises a lightweight runtime system and the underlying client-server technology that creates and manages containers.

Docker Engine consists of three components:

Server. Docker's server is a daemon process (dockerd) responsible for creating and managing containers.
Rest API. Docker uses REST API to establish communication with the clients that instruct dockerd what to do.
Command-Line Interface (CLI). Each Docker client communicates with the daemon by issuing Docker CLI commands.
The sections below explain some of the essential concepts in Docker architecture.

Docker Daemon
The Docker daemon is a persistent background process created by the Docker Engine. This process accepts and fulfills API requests related to building, running, and managing Docker containers and images. The daemon uses a REST API that enables users to issue Docker CLI commands or use a client library to perform container-related actions.

Docker Host
A Docker host is any system with a running Docker instance. Hosts interact with the Docker daemon to create and manage containers.

While the Docker host is commonly a single, independent machine, container orchestrators such as Docker Swarm and Kubernetes can distribute the role of a single host across multiple systems. Distributed hosts facilitate scaling and container orchestration.

Docker Client
A Docker client is a tool that enables users to interact with the Docker daemon on their system. The client features a set of Docker CLI commands that enable the creation and management of containers.

Docker Objects
Docker objects are components of a Docker deployment that help package and distribute applications. The following sections present the essential Docker objects.

Docker Container
A container is a runtime environment containing the application code alongside the dependencies (libraries and files). Docker containers are designed to comply with the Open Container Initiative (OCI) rules, making them compatible with other OCI container engines.

Docker Image
A Docker image is a template for building containers. Like virtual machine snapshots, Docker images are immutable, read-only files consisting of the source code, libraries, dependencies, tools, and other files necessary to run an application.

Docker CLI commands such as docker run and docker create use the app data in the image to create a Docker container that runs the given app.

From Dockefiles to Docker images to Docker containers.
Note: Maintaining small images is essential for producing lightweight, fast containers. Utilizing a lighter image base, avoiding unnecessary layers, and using the .dockerignore file are just a few ways of keeping your Docker images small.

Dockerfile
A Dockerfile is a script that consists of a set of instructions on how to build a Docker image. These instructions include specifying the OS, languages, Docker environment variables, file locations, network ports, and other components needed to run the image. All the commands in the file are grouped and executed automatically.

A Docker image has multiple layers. A new read-write layer (container layer) is added once a user runs an image to create a container. The additional layer accepts changes, which the user can commit to create a new Docker image for future use.

Docker image layers.
Docker Volume
Instead of adding new layers to an image, a better solution to preserve data produced by a running container is using Docker volumes. This helpful tool allows users to save data, share it between containers, and mount it to new ones.

Volumes are independent of the container life cycle as they are stored on the host.

Docker Tools
Docker features a rich ecosystem of tools to enhance its functionality and make it easier to work with many containers. Below are some of the most popular Docker tools available at the moment.

Docker Desktop
Docker Desktop is an application that allows users to quickly manage containers on Windows and macOS using a graphical user interface. It is a simple way of installing and setting up the entire Docker development environment.

It includes Docker Engine, Docker Compose, Docker CLI client, Docker Content Trust, Kubernetes, and Credential Helper.

Docker Registry
Docker Registry is a system that organizes storage and distribution of Docker images. Each registry consists of repositories that host images. Users can pull images from a repository to their local system or push the image to the repository for easier access.

Docker Hub
Docker Hub is the largest repository of container images. It supplies over 100,000 images created by open-source projects, software vendors, and the Docker community.

The platform allows users to ship their applications anywhere quickly, collaborate with teammates, and automate builds for faster integration to a development pipeline.

Like in GitHub, developers push and pull container images from Docker Hub and decide whether to keep them public or private.

Docker hub front page.
Docker Swarm
Docker Swarm is a tool that allows developers to create a cluster of Docker nodes, i.e., physical machines with Docker installed, and manage it as a single system. Each swarm consists of:

A swarm manager that controls the nodes in the swarm and enables the orchestration and scheduling of containers.
Worker nodes that receive and execute tasks from the swarm manager.
Docker Compose
Docker Compose is a tool that simplifies running and managing multiple containers simultaneously. It strings multiple containers and controls them through a single coordinated command.

With Docker Compose, users can launch, execute, manage, and close containers with one command. These actions are performed using a YAML file to configure the application's services.
